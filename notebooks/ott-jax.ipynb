{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "import e3nn_jax as e3nn\n",
    "\n",
    "from ott.geometry import costs, grid, pointcloud\n",
    "from ott.problems.linear import linear_problem\n",
    "from ott.solvers.linear import sinkhorn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D grid example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_radii = 3\n",
    "grid_size = (num_radii,)\n",
    "radii = jnp.asarray([1.0, 2.0, 3.0])\n",
    "geom = grid.Grid(x=[radii])\n",
    "\n",
    "def compute_cost(predicted_logits):\n",
    "    predicted_histogram = jax.nn.softmax(predicted_logits)\n",
    "    target_histogram = jax.nn.one_hot(jnp.array([1]), num_radii).reshape(-1)\n",
    "    prob = linear_problem.LinearProblem(geom, a=predicted_histogram, b=target_histogram)\n",
    "    solver = sinkhorn.Sinkhorn()\n",
    "    out = solver(prob)\n",
    "    return out.reg_ot_cost\n",
    "\n",
    "def optimize_predicted_logits():\n",
    "    tx = optax.adam(1e-2)\n",
    "    init_logits = jnp.ones(num_radii)\n",
    "    opt_state = tx.init(init_logits)\n",
    "\n",
    "    @jax.jit\n",
    "    def update_fn(predicted_logits, opt_state):\n",
    "        loss, grads = jax.value_and_grad(compute_cost)(predicted_logits)\n",
    "        updates, new_opt_state = tx.update(grads, opt_state)\n",
    "        new_predicted_logits = optax.apply_updates(predicted_logits, updates)\n",
    "        return new_predicted_logits, new_opt_state, loss\n",
    "\n",
    "    predicted_logits = init_logits\n",
    "    for i in range(1000):\n",
    "        predicted_logits, opt_state, loss = update_fn(predicted_logits, opt_state)\n",
    "        if i % 100 == 0:\n",
    "            print(\"Loss at step {}: {}\".format(i, loss))\n",
    "            print(\"Predicted histogram: {}\".format(jax.nn.softmax(predicted_logits)))\n",
    "    \n",
    "    return predicted_logits\n",
    "\n",
    "predicted_logits = optimize_predicted_logits()\n",
    "predicted_histogram = jax.nn.softmax(predicted_logits)\n",
    "print(predicted_histogram)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D grid example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = (num_radii,)\n",
    "radii = jnp.asarray([1.0, 2.0, 3.0])\n",
    "geom = grid.Grid(x=[radii])\n",
    "\n",
    "def compute_cost(predicted_irreps):\n",
    "    predicted_histogram = jax.nn.softmax(predicted_irreps)\n",
    "    target_histogram = jax.nn.one_hot(jnp.array([1]), num_radii).reshape(-1)\n",
    "    prob = linear_problem.LinearProblem(geom, a=predicted_histogram, b=target_histogram)\n",
    "    solver = sinkhorn.Sinkhorn()\n",
    "    out = solver(prob)\n",
    "    return out.reg_ot_cost\n",
    "\n",
    "\n",
    "def optimize_predicted_irreps():\n",
    "    tx = optax.adam(1e-2)\n",
    "    init_irreps = jnp.ones(num_radii)\n",
    "    opt_state = tx.init(init_irreps)\n",
    "\n",
    "    @jax.jit\n",
    "    def update_fn(predicted_irreps, opt_state):\n",
    "        loss, grads = jax.value_and_grad(compute_cost)(predicted_irreps)\n",
    "        updates, new_opt_state = tx.update(grads, opt_state)\n",
    "        new_predicted_irreps = optax.apply_updates(predicted_irreps, updates)\n",
    "        return new_predicted_irreps, new_opt_state, loss\n",
    "\n",
    "    predicted_irreps = init_irreps\n",
    "    for i in range(1000):\n",
    "        predicted_irreps, opt_state, loss = update_fn(predicted_irreps, opt_state)\n",
    "        if i % 100 == 0:\n",
    "            print(\"Loss at step {}: {}\".format(i, loss))\n",
    "            print(\"Predicted histogram: {}\".format(jax.nn.softmax(predicted_irreps)))\n",
    "    \n",
    "    return predicted_irreps\n",
    "\n",
    "predicted_irreps = optimize_predicted_irreps()\n",
    "predicted_histogram = jax.nn.softmax(predicted_logits)\n",
    "print(predicted_histogram)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
