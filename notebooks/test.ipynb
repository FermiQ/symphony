{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jraph\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import e3nn_jax as e3nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_radius_weights = e3nn.IrrepsArray(\"0e\", jnp.asarray([1.]))\n",
    "log_angular_coeffs = e3nn.IrrepsArray(\"0e + 1o\", jnp.arange(4).astype(float))\n",
    "x = e3nn.concatenate([log_radius_weights, log_angular_coeffs], axis=0)\n",
    "x, x.simplify(), e3nn.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_radius_weights = e3nn.IrrepsArray(\"0e\", jnp.arange(64).reshape((64, 1)))\n",
    "log_angular_coeffs = e3nn.IrrepsArray(\"0e + 1o\", jnp.arange(4))\n",
    "log_angular_coeffs = e3nn.IrrepsArray(log_angular_coeffs.irreps, jnp.tile(log_angular_coeffs.array, (64, 1)))\n",
    "print(log_angular_coeffs.shape)\n",
    "e3nn.concatenate([log_radius_weights, log_angular_coeffs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = e3nn.IrrepsArray(\"0e + 1o\", jnp.asarray([1.0, 1.0, 2.0, 3.0]))\n",
    "coeffs_on_grid = e3nn.to_s2grid(coeffs, res_beta=30, res_alpha=59, quadrature=\"soft\").grid_values\n",
    "\n",
    "scaled_coeffs = coeffs * 2.0\n",
    "scaled_coeffs_on_grid = e3nn.to_s2grid(scaled_coeffs, res_beta=30, res_alpha=59, quadrature=\"soft\").grid_values\n",
    "\n",
    "scaled_coeffs_on_grid / coeffs_on_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import train\n",
    "import models\n",
    "import datatypes\n",
    "import analyses.generate_plots as generate_plots\n",
    "import input_pipeline_tf\n",
    "import configs.mace as mace\n",
    "import analyses.analysis as analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = mace.get_config()\n",
    "print(config.train_molecules)\n",
    "config.train_molecules = (0, 2976)\n",
    "datasets = input_pipeline_tf.get_datasets(None, config)\n",
    "for step, _ in enumerate(datasets['train']):\n",
    "    if step % 50000 == 0:\n",
    "        print(step)\n",
    "print(step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"../potato_workdirs/extras/sample_complexity\"\n",
    "results = analysis.get_results_as_dataframe(generate_plots.ALL_MODELS, generate_plots.ALL_METRICS, basedir)\n",
    "results['val'][results['val']['model'] == 'mace'].sort_values(by='max_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['val'].to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval():\n",
    "    for x in datasets[\"val\"].take(10).as_numpy_iterator():\n",
    "        mask = jraph.get_graph_padding_mask(x)\n",
    "        print(x.n_node[mask].sum())\n",
    "\n",
    "eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "ds = tf.data.Dataset.range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ds.take(3).as_numpy_iterator():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = mace.get_config()\n",
    "datasets = input_pipeline_tf.get_raw_qm9_datasets(config)\n",
    "for x in datasets[\"val\"].take(10).as_numpy_iterator():\n",
    "    print(x['target_positions'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets['val'].map(\n",
    "    input_pipeline_tf._convert_to_graphstuple,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "ds_b = jraph.dynamically_batch(graphs_tuple_iterator=iter(ds),\n",
    "                                n_node=config.max_n_nodes,\n",
    "                                n_edge=config.max_n_edges,\n",
    "                                n_graph=config.max_n_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, x in enumerate(ds_b):\n",
    "    mask = jraph.get_graph_padding_mask(x)\n",
    "    print(x.n_node[mask].sum())\n",
    "    if step == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "example_graph = next(ds.as_numpy_iterator())\n",
    "example_padded_graph = jraph.pad_with_graphs(\n",
    "    example_graph, n_node=config.max_n_nodes, n_edge=config.max_n_edges, n_graph=config.max_n_graphs\n",
    ")\n",
    "padded_graphs_spec = input_pipeline_tf._specs_from_graphs_tuple(example_padded_graph)\n",
    "\n",
    "# Batch and pad each split separately.\n",
    "batching_fn = functools.partial(\n",
    "    jraph.dynamically_batch,\n",
    "    graphs_tuple_iterator=iter(ds),\n",
    "    n_node=config.max_n_nodes,\n",
    "    n_edge=config.max_n_edges,\n",
    "    n_graph=config.max_n_graphs,\n",
    ")\n",
    "ds_tf = tf.data.Dataset.from_generator(\n",
    "    batching_fn, output_signature=padded_graphs_spec\n",
    ")\n",
    "ds_tf = ds_tf.take(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, x in enumerate(ds_tf.as_numpy_iterator()):\n",
    "    mask = jraph.get_graph_padding_mask(x)\n",
    "    print(x.n_node[mask].sum())\n",
    "    if step == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mimic what we do in train.py.\n",
    "config = mace.get_config()\n",
    "\n",
    "config.max_n_graphs = 32\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng, dataset_rng = jax.random.split(rng)\n",
    "\n",
    "# Obtain graphs.\n",
    "datasets = input_pipeline_tf.get_datasets(dataset_rng, config)\n",
    "train_iter = datasets[\"train\"].as_numpy_iterator()\n",
    "init_graphs = next(train_iter)\n",
    "\n",
    "# Set up dummy variables to obtain the structure.\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "net = train.create_model(config, run_in_evaluation_mode=False)\n",
    "params = jax.jit(net.init)(init_rng, init_graphs)\n",
    "\n",
    "#ds = ds.shuffle(buffer_size=5, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in datasets[\"train_eval_final\"].as_numpy_iterator():\n",
    "    mask = jraph.get_graph_padding_mask(x)\n",
    "    print(x.n_node[mask].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "ds = tf.data.Dataset.from_tensor_slices([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "ds = ds.shuffle(buffer_size=5, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ds.as_numpy_iterator():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"padding\")\n",
    "print(\"nodes\", config.max_n_nodes)\n",
    "print(\"edges\", config.max_n_edges)\n",
    "print(\"graphs\", config.max_n_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for step, graphs in enumerate(datasets[\"train\"].as_numpy_iterator()):\n",
    "    if step % 1000 == 1:\n",
    "        print(step, count / step)\n",
    "    if step == 10000:\n",
    "        break\n",
    "\n",
    "    graphs = jax.tree_map(jnp.array, graphs)\n",
    "    graphs = datatypes.Fragments.from_graphstuple(graphs)\n",
    "    count += jraph.get_graph_padding_mask(graphs).sum()\n",
    "\n",
    "print(count / step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = jraph.GraphsTuple(\n",
    "    nodes=jnp.array([[1, 2, 3], [1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
    "    edges=jnp.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
    "    globals=jnp.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
    "    n_node=jnp.array([2, 1, 1]),\n",
    "    n_edge=jnp.array([1, 1, 1]),\n",
    "    senders=jnp.array([0, 0, 0]),\n",
    "    receivers=jnp.array([0, 0, 0]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_graphs = 4\n",
    "rng, *species_rngs = jax.random.split(jax.random.PRNGKey(0), num_graphs + 1)\n",
    "\n",
    "target_species_probs = jnp.ones((num_graphs, models.NUM_ELEMENTS)) / models.NUM_ELEMENTS\n",
    "target_species = jax.vmap(lambda key, p: jax.random.choice(\n",
    "    key, models.NUM_ELEMENTS, p=p))((species_rngs,), target_species_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3nn.IrrepsArray(\"10x0e\", jnp.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "myhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results.\n",
    "results = analysis.get_results_as_dataframe(generate_plots.ALL_MODELS, generate_plots.ALL_METRICS, \"../potato_workdirs/v4/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['val'].sort_values('total_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "seed, start, end = [int(val) for val in re.findall(r'\\d+', \"fragments_seed01_from130944_to133920\")]\n",
    "start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_sample(probabilities, segment_ids, num_segments, rng):\n",
    "    \"\"\"Sample from a categorical distribution across each segment.\n",
    "    Args:\n",
    "        segment_ids: A 1D array of segment ids.\n",
    "        probs: A 1D array of probabilities.\n",
    "    Returns:\n",
    "        A 1D array of samples.\n",
    "    \"\"\"\n",
    "    def sample_for_segment(rng, i):\n",
    "        return jax.random.choice(rng, node_indices, p=jnp.where(i == segment_ids, probabilities, 0.))\n",
    "    \n",
    "    node_indices = jnp.arange(len(segment_ids))\n",
    "    rngs = jax.random.split(rng, num_segments)\n",
    "    return jax.vmap(sample_for_segment)(rngs, jnp.arange(num_segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_logits = graphs.nodes.sum(axis=1)\n",
    "probs = jraph.partition_softmax(focus_logits, graphs.n_node)\n",
    "print(probs)\n",
    "for seed in range(100):\n",
    "    print(segment_sample(probs, jnp.asarray([0, 0, 1, 2]), 3, jax.random.PRNGKey(seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = jnp.asarray([2, 3, 1, 4])\n",
    "segment_max = e3nn.scatter_max(nodes, nel=graphs.n_node)\n",
    "segment_max_expanded = e3nn.scatter_max(nodes, map_back=True, nel=graphs.n_node)\n",
    "print(segment_max_expanded)\n",
    "# segment_max_expanded = jnp.asarray([segment_max[0], segment_max[0], segment_max[1], segment_max[2]])\n",
    "\n",
    "expected = 0 + jnp.log(1 + e3nn.scatter_sum(jnp.exp(nodes - 0), nel=graphs.n_node))\n",
    "computed = segment_max + jnp.log(jnp.exp(-segment_max) + e3nn.scatter_sum(jnp.exp(nodes - segment_max_expanded), nel=graphs.n_node))\n",
    "\n",
    "expected, computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.load_from_workdir(\"/Users/ameyad/Documents/spherical-harmonic-net/potato_workdirs/workdirs/mace/interactions=1/l=0/channels=32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax = 3\n",
    "irreps = e3nn.Irreps(e3nn.Irrep.iterator(lmax))\n",
    "e3nn.IrrepsArray(irreps=irreps, array=jnp.ones((10, irreps.dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3nn.scatter_sum(data=graphs.nodes, nel=graphs.n_node)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c45d96c58491a395ddcd8e473c3845279123da787cb66983d65c138d89f394de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
