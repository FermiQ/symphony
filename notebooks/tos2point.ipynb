{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import e3nn_jax as e3nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import distrax\n",
    "import optax\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RationalQuadraticSpline(hk.Module):\n",
    "    \"\"\"A rational quadratic spline flow.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_bins: int,\n",
    "        range_min: float,\n",
    "        range_max: float,\n",
    "        num_layers: int,\n",
    "        num_param_mlp_layers: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_bins = num_bins\n",
    "        self.range_min = range_min\n",
    "        self.range_max = range_max\n",
    "        self.num_layers = num_layers\n",
    "        self.num_param_mlp_layers = num_param_mlp_layers\n",
    "\n",
    "    def create_flow(self, conditioning: e3nn.IrrepsArray) -> distrax.Bijector:\n",
    "        \"\"\"Creates a flow with the given conditioning.\"\"\"\n",
    "        if not conditioning.irreps.is_scalar():\n",
    "            raise ValueError(\"Conditioning for flow must be scalars only.\")\n",
    "        conditioning = conditioning.array\n",
    "\n",
    "        layers = []\n",
    "        for _ in range(self.num_layers):\n",
    "            param_dims = self.num_bins * 3 + 1\n",
    "            params = hk.nets.MLP(\n",
    "                [param_dims] * self.num_param_mlp_layers,\n",
    "                activate_final=False,\n",
    "                w_init=hk.initializers.RandomNormal(1e-4),\n",
    "                b_init=hk.initializers.RandomNormal(1e-4),\n",
    "            )(conditioning)\n",
    "            layer = distrax.RationalQuadraticSpline(\n",
    "                params,\n",
    "                self.range_min,\n",
    "                self.range_max,\n",
    "                boundary_slopes=\"unconstrained\",\n",
    "                min_bin_size=1e-2,\n",
    "            )\n",
    "            layers.append(layer)\n",
    "\n",
    "        flow = distrax.Inverse(distrax.Chain(layers))\n",
    "        return flow\n",
    "\n",
    "    def create_distribution(\n",
    "        self, conditioning: e3nn.IrrepsArray\n",
    "    ) -> distrax.Distribution:\n",
    "        \"\"\"Creates a distribution by composing a base distribution with a flow.\"\"\"\n",
    "        flow = self.create_flow(conditioning)\n",
    "        base_distribution = distrax.Independent(\n",
    "            distrax.Uniform(low=self.range_min, high=self.range_max),\n",
    "            reinterpreted_batch_ndims=0,\n",
    "        )\n",
    "        dist = distrax.Transformed(base_distribution, flow)\n",
    "        return dist\n",
    "\n",
    "    def forward(\n",
    "        self, base_samples: jnp.ndarray, conditioning: e3nn.IrrepsArray\n",
    "    ) -> jnp.ndarray:\n",
    "        \"\"\"Applies the flow to the given samples from the base distribution.\"\"\"\n",
    "        flow = self.create_flow(conditioning)\n",
    "        return flow.forward(base_samples)\n",
    "\n",
    "    def log_prob(\n",
    "        self, samples: jnp.ndarray, conditioning: e3nn.IrrepsArray\n",
    "    ) -> jnp.ndarray:\n",
    "        \"\"\"Computes the log probability of the given samples.\"\"\"\n",
    "        assert conditioning.shape[:-1] == samples.shape[:-1], (\n",
    "            conditioning.shape,\n",
    "            samples.shape,\n",
    "        )\n",
    "        dist = self.create_distribution(conditioning)\n",
    "        return dist.log_prob(samples)\n",
    "\n",
    "    def sample(self, conditioning: e3nn.IrrepsArray, num_samples: int) -> jnp.ndarray:\n",
    "        \"\"\"Samples from the learned distribution.\"\"\"\n",
    "        dist = self.create_distribution(conditioning)\n",
    "        rng = hk.next_rng_key()\n",
    "        return dist.sample(seed=rng, sample_shape=(num_samples,))\n",
    "\n",
    "    def langevin_sample(\n",
    "        self,\n",
    "        conditioning: e3nn.IrrepsArray,\n",
    "        num_samples: int,\n",
    "        beta: float,\n",
    "        init_step_size: float,\n",
    "        num_sampling_steps: int,\n",
    "    ) -> jnp.ndarray:\n",
    "        \"\"\"Samples from the learned distribution using Langevin dynamics.\"\"\"\n",
    "        dist = self.create_distribution(conditioning)\n",
    "\n",
    "        def score_fn(samples):\n",
    "            return jax.grad(dist.log_prob)(samples)\n",
    "\n",
    "        def update(carry, rng):\n",
    "            samples, step_size = carry\n",
    "            new_samples = samples + step_size * score_fn(samples)\n",
    "            new_samples += jnp.sqrt(2 * step_size / beta) * jax.random.normal(\n",
    "                rng, samples.shape\n",
    "            )\n",
    "            new_samples = self.range_min + new_samples % (\n",
    "                self.range_max - self.range_min\n",
    "            )\n",
    "\n",
    "            # jax.debug.print('samples={x}', x=samples)\n",
    "            # jax.debug.print('new_samples={x}', x=new_samples)\n",
    "            log_acceptance_ratio = dist.log_prob(new_samples) - dist.log_prob(samples)\n",
    "\n",
    "            acceptance_ratio = jnp.exp(log_acceptance_ratio)\n",
    "            # jax.debug.print('acceptance_ratio={x}', x=acceptance_ratio)\n",
    "            accept = jax.random.bernoulli(rng, acceptance_ratio)\n",
    "            samples = jnp.where(accept, new_samples, samples)\n",
    "            step_size = step_size * (1 - 1 / (num_sampling_steps))\n",
    "            return (samples, step_size), samples\n",
    "\n",
    "        rng = hk.next_rng_key()\n",
    "\n",
    "        init_samples = dist.sample(seed=rng, sample_shape=(num_samples,))\n",
    "\n",
    "        def sample_single_seed_fn(init_sample):\n",
    "            return jax.lax.scan(\n",
    "                update,\n",
    "                (init_sample, init_step_size),\n",
    "                jax.random.split(rng, num_sampling_steps),\n",
    "            )\n",
    "\n",
    "        return jax.vmap(sample_single_seed_fn)(init_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_radii = jnp.array([1.0, 1.5, 2.0, 2.5, 3.0])\n",
    "\n",
    "conditioning = e3nn.IrrepsArray(\"0e\", jnp.asarray([1.0]))\n",
    "\n",
    "\n",
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def log_probs_fn(r, conditioning):\n",
    "    flow = RationalQuadraticSpline(\n",
    "        num_bins=8, range_min=0.0, range_max=4.0, num_layers=1, num_param_mlp_layers=1\n",
    "    )\n",
    "    return flow.log_prob(r, conditioning)\n",
    "\n",
    "\n",
    "params = log_probs_fn.init(jax.random.PRNGKey(0), target_radii, conditioning)\n",
    "tx = optax.adam(1e-3)\n",
    "opt_state = tx.init(params)\n",
    "\n",
    "\n",
    "def train_step(params, opt_state, conditioning, target_radii):\n",
    "    def loss_fn(params):\n",
    "        return -log_probs_fn.apply(params, target_radii, conditioning).mean()\n",
    "\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params)\n",
    "    updates, opt_state = tx.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state, loss\n",
    "\n",
    "\n",
    "for step in range(10000):\n",
    "    params, opt_state, loss = train_step(params, opt_state, conditioning, target_radii)\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step}, loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hk.transform\n",
    "def sample_fn(conditioning, num_samples):\n",
    "    flow = RationalQuadraticSpline(\n",
    "        num_bins=8, range_min=0.0, range_max=4.0, num_layers=1, num_param_mlp_layers=1\n",
    "    )\n",
    "    return flow.sample(conditioning, num_samples)\n",
    "\n",
    "\n",
    "@hk.transform\n",
    "def langevin_sample_fn(\n",
    "    conditioning, num_samples, beta, init_step_size, num_sampling_steps\n",
    "):\n",
    "    flow = RationalQuadraticSpline(\n",
    "        num_bins=8, range_min=0.0, range_max=4.0, num_layers=1, num_param_mlp_layers=1\n",
    "    )\n",
    "    return flow.langevin_sample(\n",
    "        conditioning, num_samples, beta, init_step_size, num_sampling_steps\n",
    "    )\n",
    "\n",
    "\n",
    "queries = jnp.linspace(0.0, 4.0, 1000)\n",
    "queries = queries.reshape(-1, 1)\n",
    "log_probs = jax.vmap(lambda r: log_probs_fn.apply(params, r, conditioning))(queries)\n",
    "log_probs = log_probs.reshape(-1)\n",
    "probs = jnp.exp(log_probs)\n",
    "\n",
    "(samples, _), trajectory = langevin_sample_fn.apply(\n",
    "    params,\n",
    "    jax.random.PRNGKey(0),\n",
    "    conditioning,\n",
    "    num_samples=100,\n",
    "    beta=10,\n",
    "    init_step_size=1e-3,\n",
    "    num_sampling_steps=100,\n",
    ")\n",
    "samples = samples.reshape(-1)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=queries.flatten(), y=probs, mode=\"lines\"))\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=samples.flatten(), y=jnp.zeros_like(samples), mode=\"markers\")\n",
    ")\n",
    "fig.update_layout(title=\"Langevin dynamics samples\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for t in range(trajectory.shape[1]):\n",
    "    frame = go.Frame(\n",
    "        data=[\n",
    "            go.Scatter(\n",
    "                x=trajectory[:, t],\n",
    "                y=jnp.zeros_like(trajectory[:, t]),\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=5),\n",
    "            )\n",
    "        ],\n",
    "        layout=go.Layout(title=f\"Langevin Monte Carlo: Timestep {t+1}\"),\n",
    "    )\n",
    "    frames.append(frame)\n",
    "\n",
    "anim_layout = go.Layout(\n",
    "    xaxis=dict(range=[0, 4], autorange=False),\n",
    "    yaxis=dict(range=[-0.1, 0.1], autorange=False),\n",
    "    title=\"Langevin Monte Carlo Sampling of a Probability Distribution\",\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    label=\"Play\",\n",
    "                    method=\"animate\",\n",
    "                    args=[\n",
    "                        None,\n",
    "                        {\n",
    "                            \"frame\": {\"duration\": 50, \"redraw\": True},\n",
    "                            \"fromcurrent\": True,\n",
    "                            \"transition\": {\"duration\": 50, \"easing\": \"linear\"},\n",
    "                        },\n",
    "                    ],\n",
    "                ),\n",
    "                dict(\n",
    "                    label=\"Pause\",\n",
    "                    method=\"animate\",\n",
    "                    args=[\n",
    "                        [None],\n",
    "                        {\n",
    "                            \"frame\": {\"duration\": 0, \"redraw\": False},\n",
    "                            \"mode\": \"immediate\",\n",
    "                            \"transition\": {\"duration\": 0},\n",
    "                        },\n",
    "                    ],\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[frames[0].data[0]], layout=anim_layout, frames=frames)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample_fn.apply(params, jax.random.PRNGKey(0), conditioning, 100)\n",
    "samples = samples.reshape(-1)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=queries.flatten(), y=probs, mode=\"lines\"))\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=samples.flatten(), y=jnp.zeros_like(samples), mode=\"markers\")\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = dict(\n",
    "    scene=dict(\n",
    "        xaxis=dict(title=\"X\", range=[-1, 1], autorange=False),\n",
    "        yaxis=dict(title=\"Y\", range=[-1, 1], autorange=False),\n",
    "        zaxis=dict(title=\"Z\", range=[-1, 1], autorange=False),\n",
    "        aspectmode=\"cube\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = e3nn.IrrepsArray(\n",
    "    \"1o\",\n",
    "    jnp.asarray(\n",
    "        [\n",
    "            [1.0, 0.0, 0.0],\n",
    "            [0.0, 1.0 / jnp.sqrt(2), 1.0 / jnp.sqrt(2)],\n",
    "            [0.0, 0.0, 1.0],\n",
    "            [0.0, -1.0, 0.0],\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logits(coeffs, target):\n",
    "    assert target.shape == (3,)\n",
    "\n",
    "    num_channels = coeffs.shape[0]\n",
    "    assert coeffs.shape == (num_channels, coeffs.irreps.dim)\n",
    "\n",
    "    vals = e3nn.to_s2point(coeffs, target)\n",
    "    vals = vals.array.squeeze(-1)\n",
    "    assert vals.shape == (num_channels,), vals.shape\n",
    "\n",
    "    logits = jax.scipy.special.logsumexp(vals, axis=-1)\n",
    "    assert logits.shape == ()\n",
    "\n",
    "    return e3nn.IrrepsArray(\"0e\", logits)\n",
    "\n",
    "\n",
    "def loss(coeffs, targets):\n",
    "    num_targets = targets.shape[0]\n",
    "    num_channels = coeffs.shape[0]\n",
    "\n",
    "    # Compute the logits for each target.\n",
    "    logits = jax.vmap(lambda target: compute_logits(coeffs, target).array)(targets)\n",
    "    assert logits.shape == (num_targets,), logits.shape\n",
    "\n",
    "    # To compute the log-partition function, we need to integrate the signal.\n",
    "    res_beta = 100\n",
    "    res_alpha = 99\n",
    "    prob_signal = e3nn.to_s2grid(\n",
    "        coeffs, res_beta=res_beta, res_alpha=res_alpha, quadrature=\"gausslegendre\"\n",
    "    )\n",
    "    assert prob_signal.shape == (num_channels, res_beta, res_alpha), prob_signal.shape\n",
    "\n",
    "    prob_signal = prob_signal.apply(jnp.exp)\n",
    "    prob_signal = prob_signal.replace_values(jnp.sum(prob_signal.grid_values, axis=-3))\n",
    "    assert prob_signal.shape == (res_beta, res_alpha), prob_signal\n",
    "\n",
    "    log_Z = jnp.log(prob_signal.integrate().array[0])\n",
    "    assert log_Z.shape == (), log_Z.shape\n",
    "\n",
    "    return -jnp.mean(logits) + log_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(coeffs, targets, opt_state):\n",
    "    loss_value, grads = jax.value_and_grad(loss)(coeffs, targets)\n",
    "    updates, opt_state = tx.update(grads, opt_state)\n",
    "    coeffs = optax.apply_updates(coeffs, updates)\n",
    "    return coeffs, loss_value, opt_state\n",
    "\n",
    "\n",
    "lmax = 5\n",
    "irreps = e3nn.s2_irreps(lmax)\n",
    "num_channels = 5\n",
    "coeffs = e3nn.normal(\n",
    "    irreps,\n",
    "    leading_shape=(num_channels,),\n",
    "    key=jax.random.PRNGKey(0),\n",
    ")\n",
    "\n",
    "tx = optax.chain(\n",
    "    optax.adam(1e-3),\n",
    "    optax.clip_by_global_norm(1.0),\n",
    ")\n",
    "opt_state = tx.init(coeffs)\n",
    "\n",
    "for i in range(10000):\n",
    "    coeffs, loss_value, opt_state = train_step(coeffs, targets, opt_state)\n",
    "    if i % 1000 == 0:\n",
    "        print(\"loss\", loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_sig = e3nn.SphericalSignal.from_function(\n",
    "    lambda target: compute_logits(coeffs, e3nn.IrrepsArray(\"1o\", target)).array,\n",
    "    res_beta=100,\n",
    "    res_alpha=99,\n",
    "    quadrature=\"gausslegendre\",\n",
    ")\n",
    "print(logits_sig.grid_vectors.shape)\n",
    "go.Figure(\n",
    "    [\n",
    "        go.Surface(logits_sig.plotly_surface()),\n",
    "    ]\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeffs_to_prob_sig(coeffs):\n",
    "    sig = e3nn.to_s2grid(coeffs, res_beta=100, res_alpha=99, quadrature=\"gausslegendre\")\n",
    "    assert sig.shape == (num_channels, 100, 99), sig.shape\n",
    "    sig = sig.replace_values(sig.grid_values - jnp.max(sig.grid_values))\n",
    "    sig = sig.replace_values(jnp.exp(sig.grid_values))\n",
    "    sig = sig.replace_values(jnp.sum(sig.grid_values, axis=-3))\n",
    "    sig /= sig.integrate().array[0]\n",
    "    return sig\n",
    "\n",
    "\n",
    "prob_sig = coeffs_to_prob_sig(coeffs)\n",
    "go.Figure(\n",
    "    [\n",
    "        go.Surface(prob_sig.plotly_surface(scale_radius_by_amplitude=False)),\n",
    "        go.Scatter3d(\n",
    "            x=targets.array[:, 0] * 1.1,\n",
    "            y=targets.array[:, 1] * 1.1,\n",
    "            z=targets.array[:, 2] * 1.1,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=10, color=\"green\"),\n",
    "            visible=True,\n",
    "        ),\n",
    "    ],\n",
    "    layout=layout,\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_sample(coeffs, beta):\n",
    "    coeffs *= beta\n",
    "    prob_sig = coeffs_to_prob_sig(coeffs)\n",
    "    num_samples = 100\n",
    "    rngs = jax.random.split(jax.random.PRNGKey(0), num_samples)\n",
    "    beta_indices, alpha_indices = jax.vmap(prob_sig.sample)(rngs)\n",
    "    samples = jax.vmap(lambda bi, ai: prob_sig.grid_vectors[bi, ai])(\n",
    "        beta_indices, alpha_indices\n",
    "    )\n",
    "    return samples\n",
    "\n",
    "\n",
    "beta = 10\n",
    "samples = discrete_sample(coeffs, beta)\n",
    "go.Figure(\n",
    "    [\n",
    "        go.Scatter3d(\n",
    "            x=samples[:, 0],\n",
    "            y=samples[:, 1],\n",
    "            z=samples[:, 2],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=10, color=\"red\"),\n",
    "        ),\n",
    "    ],\n",
    "    layout=layout,\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def score(sample, coeffs: e3nn.IrrepsArray):\n",
    "    return e3nn.grad(compute_logits, argnums=1)(coeffs, sample)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def project_update_on_tangent_space(sample, update):\n",
    "    return update - e3nn.dot(sample, update) * sample\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def apply_exponential_map(sample, update):\n",
    "    update_norm = jnp.linalg.norm(update.array)\n",
    "    return jnp.cos(update_norm) * sample + jnp.sin(update_norm) * update / update_norm\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=(\"num_steps\"))\n",
    "def langevin_monte_carlo(init_sample, coeffs, beta, key, num_steps, init_step_size):\n",
    "    def update(state, key):\n",
    "        sample, step_size = state\n",
    "\n",
    "        # Compute Langevin dynamics update.\n",
    "        key, noise_key = jax.random.split(key)\n",
    "        update = step_size * score(sample, coeffs)\n",
    "        update += jnp.sqrt(2 * step_size / beta) * e3nn.normal(\"1o\", noise_key)\n",
    "        update = project_update_on_tangent_space(sample, update)\n",
    "\n",
    "        new_sample = apply_exponential_map(sample, update)\n",
    "\n",
    "        # Apply Metropolis-Hastings correction.\n",
    "        key, mh_key = jax.random.split(key)\n",
    "        log_acceptance_ratio = (\n",
    "            compute_logits(coeffs, new_sample) - compute_logits(coeffs, sample)\n",
    "        ).array\n",
    "        log_acceptance_ratio = jnp.minimum(0, log_acceptance_ratio)\n",
    "        acceptance_ratio = jnp.exp(log_acceptance_ratio)\n",
    "        acceptance = jax.random.bernoulli(mh_key, acceptance_ratio)\n",
    "        new_sample = jnp.where(acceptance, new_sample.array, sample.array)\n",
    "        new_sample = e3nn.IrrepsArray(\"1o\", new_sample)\n",
    "\n",
    "        new_step_size = step_size * (1 - 1 / (num_steps))\n",
    "        return (new_sample, new_step_size), new_sample\n",
    "\n",
    "    return jax.lax.scan(\n",
    "        update, (init_sample, init_step_size), jax.random.split(key, num_steps)\n",
    "    )\n",
    "\n",
    "\n",
    "def sample_from_uniform_distribution_on_sphere(rng):\n",
    "    z = jax.random.uniform(rng, (3,), minval=-1, maxval=1)\n",
    "    return z / jnp.linalg.norm(z)\n",
    "\n",
    "\n",
    "beta = 10\n",
    "step_size = 1.0\n",
    "num_steps = 1000\n",
    "num_samples = 100\n",
    "key = jax.random.PRNGKey(0)\n",
    "init_samples = e3nn.IrrepsArray(\n",
    "    \"1o\",\n",
    "    jax.vmap(sample_from_uniform_distribution_on_sphere)(\n",
    "        jax.random.split(key, num_samples)\n",
    "    ),\n",
    ")\n",
    "keys = jax.random.split(key, num_samples)\n",
    "(samples, _), trajectory = jax.vmap(\n",
    "    lambda sample, key: langevin_monte_carlo(\n",
    "        sample, coeffs, beta, key, num_steps, step_size\n",
    "    )\n",
    ")(init_samples, keys)\n",
    "\n",
    "samples = samples.array\n",
    "go.Figure(\n",
    "    [\n",
    "        go.Scatter3d(\n",
    "            x=samples[:, 0],\n",
    "            y=samples[:, 1],\n",
    "            z=samples[:, 2],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=10, color=\"red\"),\n",
    "        ),\n",
    "    ],\n",
    "    layout=layout,\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory = trajectory.array.transpose(1, 0, 2)\n",
    "\n",
    "# Assuming your numpy array is named 'data' with shape (100, 10, 3)\n",
    "x = plot_trajectory[:, :, 0]\n",
    "y = plot_trajectory[:, :, 1]\n",
    "z = plot_trajectory[:, :, 2]\n",
    "\n",
    "frames = []\n",
    "for t in range(plot_trajectory.shape[0]):\n",
    "    frame = go.Frame(\n",
    "        data=[\n",
    "            go.Scatter3d(x=x[t], y=y[t], z=z[t], mode=\"markers\", marker=dict(size=5))\n",
    "        ],\n",
    "        layout=go.Layout(title=f\"Langevin Monte Carlo: Timestep {t+1}\"),\n",
    "    )\n",
    "    frames.append(frame)\n",
    "\n",
    "anim_layout = go.Layout(\n",
    "    scene=layout[\"scene\"],\n",
    "    title=\"Langevin Monte Carlo Sampling of a Probability Distribution\",\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    label=\"Play\",\n",
    "                    method=\"animate\",\n",
    "                    args=[\n",
    "                        None,\n",
    "                        {\n",
    "                            \"frame\": {\"duration\": 50, \"redraw\": True},\n",
    "                            \"fromcurrent\": True,\n",
    "                            \"transition\": {\"duration\": 50, \"easing\": \"linear\"},\n",
    "                        },\n",
    "                    ],\n",
    "                ),\n",
    "                dict(\n",
    "                    label=\"Pause\",\n",
    "                    method=\"animate\",\n",
    "                    args=[\n",
    "                        [None],\n",
    "                        {\n",
    "                            \"frame\": {\"duration\": 0, \"redraw\": False},\n",
    "                            \"mode\": \"immediate\",\n",
    "                            \"transition\": {\"duration\": 0},\n",
    "                        },\n",
    "                    ],\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[frames[0].data[0]], layout=anim_layout, frames=frames)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
